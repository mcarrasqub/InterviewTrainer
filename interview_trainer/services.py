import google.generativeai as genai
from django.conf import settings
import logging

logger = logging.getLogger(__name__)

class GeminiService:
    """
    ü§ñ PROP√ìSITO: Maneja toda la comunicaci√≥n con Google Gemini
    üìù QU√â HACE: Env√≠a mensajes a la IA y recibe respuestas
    üîë CAMBIO: Ahora usa TU API key centralizada
    """
    
    def __init__(self):
        # üîë USA TU API KEY CENTRALIZADA (no la del usuario)
        self.api_key = settings.GEMINI_API_KEY
        if self.api_key:
            genai.configure(api_key=self.api_key)
            self.model = genai.GenerativeModel('gemini-1.5-flash')
        else:
            self.model = None
    
    def get_system_prompt(self, interview_type='general'):
        """
        üìù PROP√ìSITO: Define la personalidad de Lumo seg√∫n el tipo de entrevista
        """
        prompts = {
            'general': """Eres Lumo, un entrenador de entrevistas de trabajo experto y amigable. Tu objetivo es ayudar a los candidatos a prepararse para entrevistas reales.

CARACTER√çSTICAS:
- Eres profesional pero cercano
- Haces preguntas relevantes y realistas
- Proporcionas feedback constructivo
- Te adaptas al nivel y √°rea del candidato
- Usas ejemplos pr√°cticos

INSTRUCCIONES:
- Siempre pregunta por el puesto/√°rea antes de empezar
- Haz una pregunta a la vez
- Da feedback espec√≠fico y actionable
- Mant√©n un tono motivador
- Usa emojis ocasionalmente para ser m√°s amigable

Responde en espa√±ol y mant√©n las respuestas concisas pero √∫tiles.""",

            'technical': """Eres Lumo, especialista en entrevistas t√©cnicas. Te enfocas en:
- Preguntas de algoritmos y estructuras de datos
- Arquitectura de software
- Mejores pr√°cticas de programaci√≥n
- Code reviews
- Resoluci√≥n de problemas t√©cnicos

Haz preguntas progresivas, desde b√°sicas hasta avanzadas.""",

            'behavioral': """Eres Lumo, experto en entrevistas comportamentales. Te especializas en:
- M√©todo STAR (Situaci√≥n, Tarea, Acci√≥n, Resultado)
- Preguntas sobre liderazgo y trabajo en equipo
- Resoluci√≥n de conflictos
- Adaptabilidad y aprendizaje

Ayuda a estructurar respuestas convincentes y aut√©nticas.""",

            'simulation': """Eres Lumo, conduciendo una simulaci√≥n completa de entrevista. Act√∫as como un entrevistador real:
- Haz preguntas variadas (t√©cnicas, comportamentales, situacionales)
- Mant√©n un flujo natural de conversaci√≥n
- Proporciona feedback al final
- Eval√∫a comunicaci√≥n, conocimientos y fit cultural"""
        }
        return prompts.get(interview_type, prompts['general'])
    
    async def generate_response(self, message, conversation_history=None, interview_type='general'):
        """
        üéØ PROP√ìSITO: Genera respuesta de la IA
        üìù QU√â HACE: Toma el mensaje del usuario y devuelve respuesta de Lumo
        """
        if not self.model:
            raise ValueError("API key de Gemini no configurada")
        
        try:
            # Construir contexto completo
            system_prompt = self.get_system_prompt(interview_type)
            full_context = f"{system_prompt}\n\n"
            
            # Agregar historial de conversaci√≥n
            if conversation_history:
                for msg in conversation_history:
                    sender = "Usuario" if msg.get('is_user') else "Lumo"
                    full_context += f"{sender}: {msg.get('content')}\n"
            
            full_context += f"Usuario: {message}\nLumo:"
            
            # Generar respuesta
            response = self.model.generate_content(
                full_context,
                generation_config=genai.types.GenerationConfig(
                    temperature=0.7,
                    top_k=40,
                    top_p=0.95,
                    max_output_tokens=1024,
                )
            )
            
            return response.text
            
        except Exception as e:
            logger.error(f"Error generando respuesta con Gemini: {str(e)}")
            raise e
