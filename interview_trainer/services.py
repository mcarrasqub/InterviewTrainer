import google.generativeai as genai
from django.conf import settings
import logging
import json
from django.utils import timezone

logger = logging.getLogger(__name__)

class GeminiService:
    """
    ü§ñ PROP√ìSITO: Maneja toda la comunicaci√≥n con Google Gemini
    üìù QU√â HACE: Env√≠a mensajes a la IA y recibe respuestas
    üîë CAMBIO: Ahora usa TU API key centralizada
    """
    
    def __init__(self):
        # üîë USA TU API KEY CENTRALIZADA (no la del usuario)
        self.api_key = settings.GEMINI_API_KEY
        if self.api_key:
            genai.configure(api_key=self.api_key)
            self.model = genai.GenerativeModel('models/gemini-2.0-flash')
            logger.info("‚úÖ Usando modelo: models/gemini-2.0-flash")
        else:
            logger.error("‚ùå API Key de Gemini no configurada")
            self.model = None
    
    def _extract_response_text(self, response):
        """
        üîß PROP√ìSITO: Extraer texto de respuesta de Gemini de forma robusta
        üìù QU√â HACE: Maneja diferentes formatos de respuesta de la API
        """
        try:
            # M√©todo 1: Acceso simple (para respuestas b√°sicas)
            return response.text.strip()
        except Exception:
            try:
                # M√©todo 2: Acceso complejo (para respuestas complejas)
                return response.candidates[0].content.parts[0].text.strip()
            except Exception as e:
                logger.error(f"‚ùå Error extrayendo texto de respuesta: {e}")
                return "Error procesando respuesta de IA"
    
    def get_system_prompt(self, interview_type='operations'):
        """
        üìù PROP√ìSITO: Define la personalidad y metodolog√≠a de Lumo seg√∫n el √°rea
        üéØ M√âTODOS: Combina STAR y SJT para evaluar competencias
        """
        # Mapeo de c√≥digos a nombres legibles
        department_names = {
            'operations': 'Operaciones y Producci√≥n',
            'sales_marketing': 'Ventas y Marketing',
            'finance': 'Finanzas y Administraci√≥n',
            'hr': 'Recursos Humanos (Talento Humano)',
            'it': 'Tecnolog√≠a de la Informaci√≥n (TI / IT)',
            'rd': 'Investigaci√≥n y Desarrollo (I+D)',
            'customer_support': 'Atenci√≥n al Cliente y Soporte',
            'management': 'Direcci√≥n General y Estrat√©gica',
            'health': 'Salud y Medicina'
        }
        
        department_name = department_names.get(interview_type, 'Operaciones y Producci√≥n')
        
        return f"""Eres Lumo, entrevistador especializado en {department_name}.

üéØ OBJETIVO: Realizar entrevista pr√°ctica con EXACTAMENTE 10 preguntas.

üìå REGLAS CR√çTICAS:
1. **L√çMITE ESTRICTO**: Solo 10 preguntas en total (¬°NO M√ÅS!)
2. **RESPUESTAS BREVES**: M√°ximo 2-3 l√≠neas por respuesta
3. **UNA pregunta por mensaje**: Sin feedback extenso entre preguntas
4. **SIN comentarios largos**: Ir directo a la siguiente pregunta

üìå COMPETENCIAS A EVALUAR:
- Comunicaci√≥n, pensamiento cr√≠tico, adaptabilidad, trabajo en equipo, inteligencia emocional

üìå TIPOS DE PREGUNTAS:
- Experiencias pasadas: "Cu√©ntame de una situaci√≥n donde..."
- Escenarios hipot√©ticos: "¬øQu√© har√≠as si...?"
- Espec√≠ficas de {department_name}

ÔøΩ ESTILO REQUERIDO:
- Profesional pero cercano
- M√°ximo 50-80 palabras por respuesta
- Una sola pregunta directa
- Sin an√°lisis extenso de respuestas
- Emojis ocasionales (1-2 m√°ximo)

IMPORTANTE: Despu√©s de la pregunta 10, finaliza amablemente la entrevista."""

    async def generate_initial_welcome(self, interview_type='operations'):
        """
        üéØ PROP√ìSITO: Genera SOLO el mensaje inicial de bienvenida
        üìù QU√â HACE: Crea un saludo espec√≠fico para iniciar la entrevista
        """
        if not self.model:
            raise ValueError("API key de Gemini no configurada")
        
        try:
            # Mapeo de tipos a nombres
            department_names = {
                'operations': 'Operaciones y Producci√≥n',
                'sales_marketing': 'Ventas y Marketing', 
                'finance': 'Finanzas y Administraci√≥n',
                'hr': 'Recursos Humanos (Talento Humano)',
                'it': 'Tecnolog√≠a de la Informaci√≥n (TI / IT)',
                'rd': 'Investigaci√≥n y Desarrollo (I+D)',
                'customer_support': 'Atenci√≥n al Cliente y Soporte',
                'management': 'Direcci√≥n General y Estrat√©gica',
                'health': 'Salud y Medicina'
            }
            
            department_name = department_names.get(interview_type, 'Operaciones y Producci√≥n')
            
            # Prompt espec√≠fico para mensaje inicial
            initial_prompt = f"""Eres Lumo, entrevistador especializado en {department_name}.

TAREA: Genera UN saludo inicial breve y profesional.

REQUISITOS:
1. M√°ximo 2-3 l√≠neas
2. Pres√©ntate como Lumo
3. Haz la primera pregunta: "Cu√©ntame sobre ti y por qu√© te interesa {department_name}"
4. Tono profesional pero amigable
5. Solo 1 emoji m√°ximo

FORMATO EJEMPLO:
¬°Hola! Soy Lumo, tu entrevistador para {department_name}. Para comenzar, ¬øpodr√≠as contarme sobre ti y por qu√© te interesa esta √°rea?

Genera SOLO el saludo inicial:"""

            # Generar mensaje inicial
            response = self.model.generate_content(
                initial_prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=0.7,  # Menos creativo para ser m√°s directo
                    top_k=30,
                    top_p=0.8,
                    max_output_tokens=100,  # Mensaje muy corto (reducido de 200)
                )
            )
            
            return self._extract_response_text(response)
            
        except Exception as e:
            logger.error(f"Error generando mensaje inicial: {str(e)}")
            # Mensaje de respaldo
            return f"¬°Hola! üëã Soy Lumo, tu entrevistador especializado en {department_name}. Me da mucho gusto conocerte y estoy emocionado de conocer m√°s sobre tu experiencia profesional. Para comenzar, ¬øpodr√≠as contarme un poco sobre ti y qu√© te motiva a aplicar para una posici√≥n en {department_name}?"
    
    def _count_ai_questions(self, conversation_history):
        """
        üî¢ PROP√ìSITO: Contar las preguntas que ha hecho Lumo en la conversaci√≥n
        üìù QU√â HACE: Analiza el historial y cuenta mensajes de IA que contienen preguntas
        ‚ö†Ô∏è  IMPORTANTE: Cuenta mensajes de IA como preguntas (1 pregunta = 1 mensaje de IA)
        """
        if not conversation_history:
            return 0
            
        ai_message_count = 0
        
        for msg in conversation_history:
            if not msg.get('is_user'):  # Es mensaje de la IA
                ai_message_count += 1
        
        # Cada mensaje de IA cuenta como una pregunta
        # (Excepto mensajes de finalizaci√≥n que contienen "completado las 10 preguntas")
        question_count = 0
        for msg in conversation_history:
            if not msg.get('is_user'):  # Es mensaje de la IA
                content = msg.get('content', '')
                # No contar mensajes de finalizaci√≥n
                if "completado las 10 preguntas" not in content.lower():
                    question_count += 1
        
        logger.info(f"üî¢ AI messages: {ai_message_count}, Questions counted: {question_count}")
        return question_count

    async def generate_response(self, message, conversation_history=None, interview_type='operations'):
        """
        üéØ PROP√ìSITO: Genera respuesta de la IA con contexto din√°mico y l√≠mite de 10 preguntas
        üìù QU√â HACE: Toma el mensaje del usuario y devuelve respuesta especializada
        üö® L√çMITE CR√çTICO: M√°ximo 10 preguntas por sesi√≥n
        """
        if not self.model:
            raise ValueError("API key de Gemini no configurada")
        
        try:
            # üî¢ CONTAR PREGUNTAS REALIZADAS (CR√çTICO)
            questions_asked = self._count_ai_questions(conversation_history or [])
            
            logger.info(f"üî¢ CONTROL DE PREGUNTAS: {questions_asked}/10 realizadas")
            logger.info(f"üìù Historial recibido: {len(conversation_history or [])} mensajes")
            
            # üö® VERIFICAR L√çMITE DE 10 PREGUNTAS
            if questions_asked >= 10:
                logger.info("üö® L√çMITE ALCANZADO: Finalizando entrevista")
                return (
                    "¬°Excelente! üéâ Hemos completado las 10 preguntas de esta entrevista. "
                    "Ha sido un placer conocerte y escuchar sobre tu experiencia profesional. "
                    "Muchas gracias por tu tiempo y por compartir tus conocimientos conmigo. "
                    "¬°Te deseo mucho √©xito en tu proceso de selecci√≥n! üåü\n\n"
                    "La entrevista ha finalizado. Puedes revisar tu evaluaci√≥n en el panel de resultados."
                )
            
            logger.info(f"‚úÖ CONTINUAR: Generando pregunta #{questions_asked + 1}/10")
            
            # Construir contexto completo con informaci√≥n din√°mica
            system_prompt = self.get_system_prompt(interview_type)
            
            # Agregar contexto de la sesi√≥n actual
            department_names = {
                'operations': 'Operaciones y Producci√≥n',
                'sales_marketing': 'Ventas y Marketing', 
                'finance': 'Finanzas y Administraci√≥n',
                'hr': 'Recursos Humanos (Talento Humano)',
                'it': 'Tecnolog√≠a de la Informaci√≥n (TI / IT)',
                'rd': 'Investigaci√≥n y Desarrollo (I+D)',
                'customer_support': 'Atenci√≥n al Cliente y Soporte',
                'management': 'Direcci√≥n General y Estrat√©gica',
                'health': 'Salud y Medicina'
            }
            
            department_name = department_names.get(interview_type, 'Operaciones y Producci√≥n')
            
            # üéØ DETECTAR SI ES EL PRIMER MENSAJE (SIN HISTORIAL)
            is_first_message = not conversation_history or len(conversation_history) == 0
            
            if is_first_message:
                # Para el primer mensaje, usar prompt espec√≠fico
                session_context = f"\nüéØ SESI√ìN INICIAL - {department_name}\nüî¢ Pregunta: 1/10\n‚ö†Ô∏è RESPUESTA BREVE: M√°ximo 2-3 l√≠neas\n\n"
                full_context = f"{system_prompt}{session_context}"
                
                # Si hay un mensaje del usuario, es porque ya escribi√≥ algo (no deber√≠a pasar, pero por si acaso)
                if message and message.strip():
                    full_context += f"El candidato dice: {message}\n"
                
                full_context += "Respuesta breve de Lumo:"
            else:
                # Para mensajes posteriores, usar el flujo normal
                remaining_questions = 10 - questions_asked
                session_context = f"\nüéØ SESI√ìN: {department_name}\nÔøΩ Preguntas: {questions_asked}/10 | Restantes: {remaining_questions}\n"
                
                if remaining_questions == 1:
                    session_context += "‚ö†Ô∏è √öLTIMA PREGUNTA - Despu√©s finaliza la entrevista\n"
                elif remaining_questions <= 3:
                    session_context += f"‚ö†Ô∏è Solo {remaining_questions} preguntas restantes\n"
                
                session_context += "‚ö†Ô∏è RESPUESTA BREVE: M√°ximo 2-3 l√≠neas, una sola pregunta\n\n"
                
                full_context = f"{system_prompt}{session_context}"
                
                # Agregar historial de conversaci√≥n (solo √∫ltimos 6 mensajes para contexto)
                if conversation_history:
                    full_context += "CONTEXTO RECIENTE:\n"
                    recent_history = conversation_history[-6:] if len(conversation_history) > 6 else conversation_history
                    for msg in recent_history:
                        sender = "Candidato" if msg.get('is_user') else "Lumo"
                        content = msg.get('content', '')[:150] + '...' if len(msg.get('content', '')) > 150 else msg.get('content', '')
                        full_context += f"{sender}: {content}\n"
                    full_context += "\n"
                
                full_context += f"Candidato: {message}\nRespuesta breve de Lumo:"
            
            # Generar respuesta
            response = self.model.generate_content(
                full_context,
                generation_config=genai.types.GenerationConfig(
                    temperature=0.6,  # Menos creativo para ser m√°s directo
                    top_k=30,
                    top_p=0.8,
                    max_output_tokens=150,  # Respuestas muy breves (reducido de 1024)
                )
            )
            
            return self._extract_response_text(response)
            
        except Exception as e:
            logger.error(f"Error generando respuesta con Gemini: {str(e)}")
            raise e
        
    async def generate_feedback_and_scores(self, session, messages):
        """
        üéØ PROP√ìSITO: Analiza toda la entrevista y genera feedback con puntajes de competencias
        üìä QU√â HACE: Eval√∫a cada competencia del 1-10 con feedback detallado en formato JSON
        """
        if not self.model:
            raise ValueError("Modelo de IA no configurado")

        try:
            # Mapeo de tipos a nombres
            department_names = {
                'operations': 'Operaciones y Producci√≥n',
                'sales_marketing': 'Ventas y Marketing', 
                'finance': 'Finanzas y Administraci√≥n',
                'hr': 'Recursos Humanos (Talento Humano)',
                'it': 'Tecnolog√≠a de la Informaci√≥n (TI / IT)',
                'rd': 'Investigaci√≥n y Desarrollo (I+D)',
                'customer_support': 'Atenci√≥n al Cliente y Soporte',
                'management': 'Direcci√≥n General y Estrat√©gica',
                'health': 'Salud y Medicina'
            }
            
            department_name = department_names.get(session.session_type, 'Operaciones y Producci√≥n')
            
            # Construir historial completo de la entrevista
            conversation_text = ""
            for msg in messages:
                sender = "Candidato" if msg.is_user else "Entrevistador"
                conversation_text += f"{sender}: {msg.content}\n"

            # Prompt de evaluaci√≥n con formato JSON
            feedback_prompt = f"""Eres un evaluador experto en {department_name}.

üéØ ANALIZA esta entrevista y genera feedback CONCISO en JSON.

ENTREVISTA:
{conversation_text}

üìä EVAL√öA (1-10):
- Comunicaci√≥n: Claridad y expresi√≥n
- Pensamiento cr√≠tico: An√°lisis y l√≥gica  
- Adaptabilidad: Flexibilidad y aprendizaje
- Trabajo en equipo: Colaboraci√≥n
- Inteligencia emocional: Autoconocimiento y empat√≠a

PUNTAJES:
- 8-10: Excelente con ejemplos concretos
- 6-7: Bueno con algunos ejemplos
- 4-5: Regular, falta profundidad
- 1-3: Deficiente, respuestas vagas

FORMATO JSON REQUERIDO:
{{
    "overall_feedback": "Feedback general en 2-3 l√≠neas m√°ximo con fortalezas y √°reas de mejora principales",
    "competency_scores": {{
        "Comunicaci√≥n": {{
            "score": 8,
            "feedback": "M√°ximo 1-2 l√≠neas sobre esta competencia",
            "example": "Ejemplo breve de la entrevista",
            "improvement_area": "√Årea espec√≠fica de mejora"
        }},
        "Pensamiento cr√≠tico": {{
            "score": 7,
            "feedback": "M√°ximo 1-2 l√≠neas sobre esta competencia",
            "example": "Ejemplo breve de la entrevista", 
            "improvement_area": "√Årea espec√≠fica de mejora"
        }},
        "Adaptabilidad": {{
            "score": 6,
            "feedback": "M√°ximo 1-2 l√≠neas sobre esta competencia",
            "example": "Ejemplo breve de la entrevista",
            "improvement_area": "√Årea espec√≠fica de mejora"
        }},
        "Trabajo en equipo": {{
            "score": 7,
            "feedback": "M√°ximo 1-2 l√≠neas sobre esta competencia",
            "example": "Ejemplo breve de la entrevista",
            "improvement_area": "√Årea espec√≠fica de mejora"
        }},
        "Inteligencia emocional": {{
            "score": 8,
            "feedback": "M√°ximo 1-2 l√≠neas sobre esta competencia",
            "example": "Ejemplo breve de la entrevista",
            "improvement_area": "√Årea espec√≠fica de mejora"
        }}
    }}
}}

REQUISITOS:
- SOLO JSON v√°lido, sin texto adicional
- Feedback breve y directo
- Tono profesional pero constructivo
- JSON sin errores de sintaxis"""

            # Generar evaluaci√≥n con configuraci√≥n espec√≠fica para JSON
            response = self.model.generate_content(
                feedback_prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=0.3,  # M√°s bajo para consistencia y brevedad
                    top_k=20,        # M√°s restrictivo para formato
                    top_p=0.8,       # M√°s determin√≠stico
                    max_output_tokens=1200,  # Reducido para respuestas m√°s breves
                )
            )
            
            # Procesar respuesta JSON
            return self._parse_json_feedback_response(self._extract_response_text(response))
            
        except Exception as e:
            logger.error(f"Error generando feedback: {str(e)}")
            raise e

    def _parse_json_feedback_response(self, response_text: str) -> dict:
        """
        üîß PROP√ìSITO: Parsea la respuesta JSON de la IA
        üìù QU√â HACE: Convierte JSON a diccionario con validaci√≥n robusta
        """
        try:
            # Limpiar respuesta (remover markdown si existe)
            json_text = response_text.strip()
            
            # Remover bloques de c√≥digo markdown si existen
            if json_text.startswith('```json'):
                json_text = json_text.replace('```json', '').replace('```', '').strip()
            elif json_text.startswith('```'):
                json_text = json_text.replace('```', '').strip()
            
            # Parsear JSON
            feedback_data = json.loads(json_text)
            
            # Validar estructura requerida
            if not isinstance(feedback_data, dict):
                raise ValueError("Respuesta no es un diccionario")
                
            if 'overall_feedback' not in feedback_data:
                raise ValueError("Falta 'overall_feedback'")
                
            if 'competency_scores' not in feedback_data:
                raise ValueError("Falta 'competency_scores'")
            
            # Validar competencias requeridas
            required_competencies = [
                'Comunicaci√≥n', 'Pensamiento cr√≠tico', 'Adaptabilidad', 
                'Trabajo en equipo', 'Inteligencia emocional'
            ]
            
            competency_scores = feedback_data['competency_scores']
            for comp in required_competencies:
                if comp not in competency_scores:
                    logger.warning(f"Competencia faltante: {comp}")
                    # Agregar competencia con valores por defecto
                    competency_scores[comp] = {
                        'score': 7,
                        'feedback': 'Evaluaci√≥n pendiente',
                        'example': 'Por determinar',
                        'improvement_area': 'An√°lisis en proceso'
                    }
                else:
                    # Validar estructura de cada competencia
                    comp_data = competency_scores[comp]
                    if not isinstance(comp_data, dict):
                        raise ValueError(f"Datos de competencia {comp} inv√°lidos")
                    
                    # Validar campos requeridos con valores por defecto
                    comp_data.setdefault('score', 7)
                    comp_data.setdefault('feedback', 'Evaluaci√≥n pendiente')
                    comp_data.setdefault('example', 'Por determinar')
                    comp_data.setdefault('improvement_area', 'An√°lisis en proceso')
                    
                    # Validar que score est√© en rango 1-10
                    try:
                        score = int(comp_data['score'])
                        if not (1 <= score <= 10):
                            logger.warning(f"Score fuera de rango para {comp}: {score}")
                            comp_data['score'] = max(1, min(10, score))
                        else:
                            comp_data['score'] = score
                    except (ValueError, TypeError):
                        logger.warning(f"Score inv√°lido para {comp}")
                        comp_data['score'] = 7
            
            return feedback_data
            
        except json.JSONDecodeError as e:
            logger.error(f"Error parseando JSON: {str(e)}")
            logger.error(f"Respuesta recibida: {response_text[:500]}...")
            return self._get_fallback_feedback()
            
        except Exception as e:
            logger.error(f"Error procesando feedback: {str(e)}")
            return self._get_fallback_feedback()
    
    def _get_fallback_feedback(self) -> dict:
        """
        üÜò PROP√ìSITO: Feedback de emergencia si falla el parsing
        """
        return {
            'overall_feedback': 'Se complet√≥ la entrevista exitosamente. El an√°lisis detallado estar√° disponible pr√≥ximamente tras revisi√≥n del sistema.',
            'competency_scores': {
                'Comunicaci√≥n': {
                    'score': 7,
                    'feedback': 'Evaluaci√≥n en proceso - sistema procesando respuestas',
                    'example': 'Por determinar tras an√°lisis completo',
                    'improvement_area': 'Recomendaciones disponibles pr√≥ximamente'
                },
                'Pensamiento cr√≠tico': {
                    'score': 7,
                    'feedback': 'Evaluaci√≥n en proceso - sistema procesando respuestas',
                    'example': 'Por determinar tras an√°lisis completo',
                    'improvement_area': 'Recomendaciones disponibles pr√≥ximamente'
                },
                'Adaptabilidad': {
                    'score': 7,
                    'feedback': 'Evaluaci√≥n en proceso - sistema procesando respuestas',
                    'example': 'Por determinar tras an√°lisis completo',
                    'improvement_area': 'Recomendaciones disponibles pr√≥ximamente'
                },
                'Trabajo en equipo': {
                    'score': 7,
                    'feedback': 'Evaluaci√≥n en proceso - sistema procesando respuestas',
                    'example': 'Por determinar tras an√°lisis completo',
                    'improvement_area': 'Recomendaciones disponibles pr√≥ximamente'
                },
                'Inteligencia emocional': {
                    'score': 7,
                    'feedback': 'Evaluaci√≥n en proceso - sistema procesando respuestas',
                    'example': 'Por determinar tras an√°lisis completo',
                    'improvement_area': 'Recomendaciones disponibles pr√≥ximamente'
                }
            }
        }

